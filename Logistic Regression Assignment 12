
# Social_Network_Ads.csv
This dataset contains information of users in a social network. Those informations are the user id the gender the age and the estimated salary. A car company has just launched their brand new luxury SUV. And we're trying to see which of these users of the social network are going to buy this brand new SUV And the last column here tells If yes or no the user bought this SUV we are going to build a model that is going to predict if a user is going to buy or not the SUV based on two variables which are going to be the age and the estimated salary. So our matrix of feature is only going to be these two columns. We want to find some correlations between the age and the estimated salary of a user and his decision to purchase yes or no the SUV.

Step 1 | Data Pre-Processing

Importing the Libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

Importing the dataset

DF=pd.read_csv("Social_Network_Ads.csv")
DF.head(10)
   User ID	Gender	Age	EstimatedSalary	Purchased
0	15624510	Male	  19	     19000	       0
1	15810944	Male	  35	     20000	       0
2	15668575	Female	26	     43000	       0
3	15603246	Female	27	     57000	       0
4	15804002	Male	  19	     76000	       0
5	15728773	Male	  27	     58000	       0
6	15598044	Female	27	     84000	       0
7	15694829	Female	32	    150000	       1
8	15600575	Male	  25	     33000	       0
9	15727311	Female	35	     65000	       0

DF.Gender.replace("Female",0,inplace=True)
DF.Gender.replace("Male",1,inplace=True)

X=DF.drop(["Purchased"],axis=1)
Y=DF["Purchased"]
Y=np.array(Y).reshape(-1,1)
Y.shape
(400, 1)
 
Splitting the dataset into the Training set and Test set

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test =train_test_split(X,Y,test_size=0.3,random_state=26)
 
Feature Scaling

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(x_train)
StandardScaler()

Step 2 | Logistic Regression Model

The library for this job which is going to be the linear model library and it is called linear because the logistic regression is a linear classifier which means that here since we're in two dimensions, our two categories of users are going to be separated by a straight line. Then import the logistic regression class. Next we will create a new object from this class which is going to be our classifier that we are going to fit on our training set.

Fitting Logistic Regression to the Training set

from sklearn.multiclass import OneVsOneClassifier
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter=100)
func=OneVsOneClassifier(model)
func.fit(x_train,y_train)
/Users/jeenajulius/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  return f(*args, **kwargs)
OneVsOneClassifier(estimator=LogisticRegression())

Step 3 | Predection

test_preds=func.predict(x_test)
from sklearn.metrics import accuracy_score
accuracy_score(y_test,test_preds)
0.7833333333333333
We predicted the test results and now we will evaluate if our logistic regression model learned and understood correctly. So this confusion matrix is going to contain the correct predictions that our model made on the set as well as the incorrect predictions.

Making the Confusion Matrix

from sklearn import metrics
confusion_matrix = metrics.confusion_matrix(y_test,test_preds)
confusion_matrix 
array([[78,  6],
       [20, 16]])
Visualization

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
cm_display.plot()
plt.show()

 
